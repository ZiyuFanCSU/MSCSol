{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.7964177987436404, RMSE: 1.0798040375783582, MSE: 1.1659767595705246, R2: 0.7468807168393925\n",
      "Fold 2 - MAE: 0.8453947597321482, RMSE: 1.1426257425913837, MSE: 1.3055935876325109, R2: 0.7068451453956552\n",
      "Fold 3 - MAE: 0.8205670052880729, RMSE: 1.1292964414502968, MSE: 1.2753104526723036, R2: 0.6993141799276142\n",
      "Fold 4 - MAE: 0.8297194056130217, RMSE: 1.12030355857161, MSE: 1.2550800633482126, R2: 0.7136912692930584\n",
      "Fold 5 - MAE: 0.8352799807222101, RMSE: 1.1108489493214966, MSE: 1.2339853882086727, R2: 0.7308740051070989\n",
      "\n",
      "Average - MAE: 0.8255, RMSE: 1.1166, MSE: 1.2472, R2: 0.7195\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/Dutta/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/Dutta/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))  \n",
    "\n",
    "    for i in range(1, folds + 1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "  \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "  \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.8048732425538889, RMSE: 1.0907005074563636, MSE: 1.1896275969655692, R2: 0.7417464095228499\n",
      "Fold 2 - MAE: 0.8387476845666791, RMSE: 1.127378781054713, MSE: 1.2709829159724102, R2: 0.7146165426469808\n",
      "Fold 3 - MAE: 0.8117984841712945, RMSE: 1.1111531100886352, MSE: 1.2346612340596463, R2: 0.7088982334482585\n",
      "Fold 4 - MAE: 0.8686896520944434, RMSE: 1.1512984831929831, MSE: 1.3254881974024635, R2: 0.6976297732330068\n",
      "Fold 5 - MAE: 0.8618642367581743, RMSE: 1.1429355692247547, MSE: 1.3063017153991139, R2: 0.7020065914691725\n",
      "\n",
      "Average - MAE: 0.8372, RMSE: 1.1247, MSE: 1.2654, R2: 0.7130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/Lee/Lee_y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/Lee/Lee_y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))  \n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    " \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    " \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.6841999615391058, RMSE: 0.989386956783766, MSE: 0.9788865502538416, R2: 0.7874957113321215\n",
      "Fold 2 - MAE: 0.7335359227389484, RMSE: 1.0400896703941684, MSE: 1.0817865224606498, R2: 0.7570982473344108\n",
      "Fold 3 - MAE: 0.6835899906450856, RMSE: 1.0058160117108432, MSE: 1.0116658494139072, R2: 0.7614748825018756\n",
      "Fold 4 - MAE: 0.7193267198286034, RMSE: 1.0113882611553084, MSE: 1.0229062148027583, R2: 0.7666547429562937\n",
      "Fold 5 - MAE: 0.7020554023067999, RMSE: 1.0078938243711928, MSE: 1.015849961205589, R2: 0.7784482425126275\n",
      "\n",
      "Average - MAE: 0.7045, RMSE: 1.0109, MSE: 1.0222, R2: 0.7702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/ExtraTrees/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/ExtraTrees/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))  \n",
    "\n",
    "    for i in range(1, folds+1 ):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "   \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    " \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.6678403266052967, RMSE: 0.9478202764663312, MSE: 0.8983632764807125, R2: 0.8049763284781333\n",
      "Fold 2 - MAE: 0.7197451786124913, RMSE: 1.0224973281033596, MSE: 1.0455007859785093, R2: 0.7652457596256764\n",
      "Fold 3 - MAE: 0.6874723241072288, RMSE: 0.9913111535350815, MSE: 0.982697803123054, R2: 0.7683048122155453\n",
      "Fold 4 - MAE: 0.6902702975955708, RMSE: 0.9815080355617544, MSE: 0.963358023872294, R2: 0.7802388699447451\n",
      "Fold 5 - MAE: 0.675726059723511, RMSE: 0.9566175787789324, MSE: 0.915117192028867, R2: 0.8004175518594395\n",
      "\n",
      "Average - MAE: 0.6882, RMSE: 0.9800, MSE: 0.9610, R2: 0.7838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/MESN/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/MESN/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))  \n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "  \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.5563427138863712, RMSE: 0.8392967395117668, MSE: 0.7044190169550825, R2: 0.8470792532269447\n",
      "Fold 2 - MAE: 0.63548018989159, RMSE: 0.932043521938954, MSE: 0.8687051267883694, R2: 0.804943033410362\n",
      "Fold 3 - MAE: 0.5704094469206721, RMSE: 0.8952729403012346, MSE: 0.8015136376356179, R2: 0.8110234375406146\n",
      "Fold 4 - MAE: 0.5751412311151983, RMSE: 0.8572249580568766, MSE: 0.7348346287156138, R2: 0.8323696027665828\n",
      "Fold 5 - MAE: 0.5586587810686972, RMSE: 0.8459547444845654, MSE: 0.7156394297159464, R2: 0.8439226464561433\n",
      "\n",
      "Average - MAE: 0.5792, RMSE: 0.8740, MSE: 0.7650, R2: 0.8279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/MSCSol/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/MSCSol/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))\n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "  \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.8276874250445628, RMSE: 1.1197593962589496, MSE: 1.2538611055102071, R2: 0.7278021010241982\n",
      "Fold 2 - MAE: 0.8422464345121411, RMSE: 1.1500700914006248, MSE: 1.3226612151342416, R2: 0.7030128212282365\n",
      "Fold 3 - MAE: 0.8281431161318593, RMSE: 1.1416350947090868, MSE: 1.3033306894714256, R2: 0.6927077196238411\n",
      "Fold 4 - MAE: 0.8588658843369261, RMSE: 1.1487930371150055, MSE: 1.3197254421239182, R2: 0.6989443723548934\n",
      "Fold 5 - MAE: 0.8665961288120275, RMSE: 1.1602963396171302, MSE: 1.3462875957289107, R2: 0.706381459558057\n",
      "\n",
      "Average - MAE: 0.8447, RMSE: 1.1441, MSE: 1.3092, R2: 0.7058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/Multi-channel GCN/Multi_y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/Multi-channel GCN/Multi_y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4)) \n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    " \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "\n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.6795348654124923, RMSE: 0.9678428356359995, MSE: 0.9367197544919322, R2: 0.7966496065781687\n",
      "Fold 2 - MAE: 0.7316953857491045, RMSE: 1.0282182106867135, MSE: 1.0572326887877868, R2: 0.7626115062907449\n",
      "Fold 3 - MAE: 0.6892633847778973, RMSE: 1.0087426903850827, MSE: 1.0175618154053347, R2: 0.7600847634406411\n",
      "Fold 4 - MAE: 0.7136127046472122, RMSE: 1.0040710553526662, MSE: 1.0081586841970167, R2: 0.7700189480712467\n",
      "Fold 5 - MAE: 0.6978908240488249, RMSE: 0.9765742452808174, MSE: 0.9536972565457981, R2: 0.7920034342002151\n",
      "\n",
      "Average - MAE: 0.7024, RMSE: 0.9971, MSE: 0.9947, R2: 0.7763\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./predictions/Ye/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./predictions/Ye/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4)) \n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    " \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "  \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgmg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
