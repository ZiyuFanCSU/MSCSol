{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7060    0.7126    0.7093       428\n",
      "           1     0.6571    0.6735    0.6652       683\n",
      "           2     0.8256    0.8044    0.8149       818\n",
      "\n",
      "    accuracy                         0.7377      1929\n",
      "   macro avg     0.7296    0.7302    0.7298      1929\n",
      "weighted avg     0.7394    0.7377    0.7385      1929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6522    0.6944    0.6726       432\n",
      "           1     0.6087    0.5971    0.6028       680\n",
      "           2     0.7815    0.7672    0.7743       816\n",
      "\n",
      "    accuracy                         0.6909      1928\n",
      "   macro avg     0.6808    0.6862    0.6832      1928\n",
      "weighted avg     0.6916    0.6909    0.6910      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7461    0.5877    0.6575       405\n",
      "           1     0.6342    0.7066    0.6685       692\n",
      "           2     0.7947    0.8014    0.7981       831\n",
      "\n",
      "    accuracy                         0.7225      1928\n",
      "   macro avg     0.7250    0.6986    0.7080      1928\n",
      "weighted avg     0.7269    0.7225    0.7220      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6870    0.7166    0.7014       441\n",
      "           1     0.6453    0.7055    0.6741       686\n",
      "           2     0.8259    0.7403    0.7808       801\n",
      "\n",
      "    accuracy                         0.7225      1928\n",
      "   macro avg     0.7194    0.7208    0.7188      1928\n",
      "weighted avg     0.7299    0.7225    0.7247      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7466    0.6187    0.6767       438\n",
      "           1     0.6539    0.7283    0.6891       703\n",
      "           2     0.8248    0.8196    0.8222       787\n",
      "\n",
      "    accuracy                         0.7407      1928\n",
      "   macro avg     0.7418    0.7222    0.7293      1928\n",
      "weighted avg     0.7447    0.7407    0.7406      1928\n",
      "\n",
      "Mean weighted accuracy: 0.7228487875600412\n",
      "Mean weighted precision: 0.7265013594084226\n",
      "Mean weighted recall: 0.7228487875600412\n",
      "Mean weighted L1 score: 0.7246686579461906\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('/MSCSol-main/dataset/benchmark.json', 'r') as f:\n",
    "    data = json.load(f) \n",
    "df = pd.read_json('/MSCSol-main/dataset/benchmark.json')\n",
    "X = df['features'].tolist()\n",
    "y = [0 if drug['LogS'] >= -1 else 1 if drug['LogS'] >= -3 else 2 for drug in data]\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10, random_state=42)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# 初始化性能指标列表\n",
    "weighted_accuracy_scores = []\n",
    "weighted_precision_scores = []\n",
    "weighted_recall_scores = []\n",
    "weighted_l1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = np.array(X)[train_index], np.array(X)[test_index]\n",
    "    y_train, y_val = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = dt_classifier.predict(X_val)\n",
    "    t = classification_report(y_val,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "    print(t)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    weighted_accuracy_scores.append(accuracy)\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n",
    "    weighted_precision_scores.append(precision)\n",
    "    weighted_recall_scores.append(recall)\n",
    "    weighted_l1_scores.append(2 * (precision * recall) / (precision + recall)) \n",
    "\n",
    "mean_weighted_accuracy = sum(weighted_accuracy_scores) / len(weighted_accuracy_scores)\n",
    "mean_weighted_precision = sum(weighted_precision_scores) / len(weighted_precision_scores)\n",
    "mean_weighted_recall = sum(weighted_recall_scores) / len(weighted_recall_scores)\n",
    "mean_weighted_l1 = sum(weighted_l1_scores) / len(weighted_l1_scores)\n",
    "\n",
    "print(\"Mean weighted accuracy:\", mean_weighted_accuracy)\n",
    "print(\"Mean weighted precision:\", mean_weighted_precision)\n",
    "print(\"Mean weighted recall:\", mean_weighted_recall)\n",
    "print(\"Mean weighted L1 score:\", mean_weighted_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6281    0.6957    0.6602       437\n",
      "           1     0.6031    0.5835    0.5931       677\n",
      "           2     0.7532    0.7301    0.7414       815\n",
      "\n",
      "    accuracy                         0.6708      1929\n",
      "   macro avg     0.6614    0.6697    0.6649      1929\n",
      "weighted avg     0.6721    0.6708    0.6710      1929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6501    0.6627    0.6563       415\n",
      "           1     0.6060    0.5790    0.5922       696\n",
      "           2     0.7298    0.7503    0.7399       817\n",
      "\n",
      "    accuracy                         0.6696      1928\n",
      "   macro avg     0.6620    0.6640    0.6628      1928\n",
      "weighted avg     0.6679    0.6696    0.6686      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6399    0.6927    0.6652       449\n",
      "           1     0.6281    0.5665    0.5957       662\n",
      "           2     0.7645    0.7907    0.7774       817\n",
      "\n",
      "    accuracy                         0.6909      1928\n",
      "   macro avg     0.6775    0.6833    0.6794      1928\n",
      "weighted avg     0.6887    0.6909    0.6889      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6004    0.6850    0.6399       419\n",
      "           1     0.6725    0.5806    0.6232       732\n",
      "           2     0.7543    0.7941    0.7737       777\n",
      "\n",
      "    accuracy                         0.6893      1928\n",
      "   macro avg     0.6757    0.6865    0.6789      1928\n",
      "weighted avg     0.6898    0.6893    0.6875      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6377    0.6934    0.6644       424\n",
      "           1     0.6037    0.5716    0.5873       677\n",
      "           2     0.7603    0.7594    0.7598       827\n",
      "\n",
      "    accuracy                         0.6789      1928\n",
      "   macro avg     0.6673    0.6748    0.6705      1928\n",
      "weighted avg     0.6784    0.6789    0.6782      1928\n",
      "\n",
      "Mean weighted accuracy: 0.6799096666085882\n",
      "Mean weighted precision: 0.679382367410774\n",
      "Mean weighted recall: 0.6799096666085882\n",
      "Mean weighted L1 score: 0.6796452858478819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('/MSCSol-main/dataset/benchmark.json', 'r') as f:\n",
    "    data = json.load(f) \n",
    "df = pd.read_json('/MSCSol-main/dataset/benchmark.json')\n",
    "X = df['features'].tolist()\n",
    "X_binary = (X > np.mean(X, axis=0)).astype(int)\n",
    "y = [0 if drug['LogS'] >= -1 else 1 if drug['LogS'] >= -3 else 2 for drug in data]\n",
    "\n",
    "bnb_classifier = BernoulliNB(alpha=0)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# 初始化性能指标列表\n",
    "weighted_accuracy_scores = []\n",
    "weighted_precision_scores = []\n",
    "weighted_recall_scores = []\n",
    "weighted_l1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = np.array(X_binary)[train_index], np.array(X_binary)[test_index]\n",
    "    y_train, y_val = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    bnb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = bnb_classifier.predict(X_val)\n",
    "    t = classification_report(y_val,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "    print(t)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    weighted_accuracy_scores.append(accuracy)\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n",
    "    weighted_precision_scores.append(precision)\n",
    "    weighted_recall_scores.append(recall)\n",
    "    weighted_l1_scores.append(2 * (precision * recall) / (precision + recall)) \n",
    "\n",
    "mean_weighted_accuracy = sum(weighted_accuracy_scores) / len(weighted_accuracy_scores)\n",
    "mean_weighted_precision = sum(weighted_precision_scores) / len(weighted_precision_scores)\n",
    "mean_weighted_recall = sum(weighted_recall_scores) / len(weighted_recall_scores)\n",
    "mean_weighted_l1 = sum(weighted_l1_scores) / len(weighted_l1_scores)\n",
    "\n",
    "print(\"Mean weighted accuracy:\", mean_weighted_accuracy)\n",
    "print(\"Mean weighted precision:\", mean_weighted_precision)\n",
    "print(\"Mean weighted recall:\", mean_weighted_recall)\n",
    "print(\"Mean weighted L1 score:\", mean_weighted_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6510    0.6970       447\n",
      "           1     0.6316    0.6914    0.6602       687\n",
      "           2     0.8099    0.8038    0.8068       795\n",
      "\n",
      "    accuracy                         0.7284      1929\n",
      "   macro avg     0.7305    0.7154    0.7213      1929\n",
      "weighted avg     0.7325    0.7284    0.7291      1929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7005    0.6316    0.6643       437\n",
      "           1     0.6280    0.6686    0.6477       697\n",
      "           2     0.8018    0.7997    0.8008       794\n",
      "\n",
      "    accuracy                         0.7142      1928\n",
      "   macro avg     0.7101    0.7000    0.7042      1928\n",
      "weighted avg     0.7160    0.7142    0.7145      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7521    0.6496    0.6971       411\n",
      "           1     0.6470    0.7006    0.6727       688\n",
      "           2     0.8092    0.8082    0.8087       829\n",
      "\n",
      "    accuracy                         0.7360      1928\n",
      "   macro avg     0.7361    0.7195    0.7262      1928\n",
      "weighted avg     0.7391    0.7360    0.7364      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7419    0.6421    0.6884       394\n",
      "           1     0.6443    0.7108    0.6759       688\n",
      "           2     0.8237    0.8061    0.8148       846\n",
      "\n",
      "    accuracy                         0.7386      1928\n",
      "   macro avg     0.7366    0.7197    0.7264      1928\n",
      "weighted avg     0.7429    0.7386    0.7394      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7368    0.6154    0.6707       455\n",
      "           1     0.6237    0.6857    0.6532       684\n",
      "           2     0.7940    0.8010    0.7975       789\n",
      "\n",
      "    accuracy                         0.7163      1928\n",
      "   macro avg     0.7182    0.7007    0.7071      1928\n",
      "weighted avg     0.7201    0.7163    0.7164      1928\n",
      "\n",
      "Mean weighted accuracy: 0.7266879298069002\n",
      "Mean weighted precision: 0.7301384363481661\n",
      "Mean weighted recall: 0.7266879298069002\n",
      "Mean weighted L1 score: 0.7284088173290495\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('/MSCSol-main/dataset/benchmark.json', 'r') as f:\n",
    "    data = json.load(f) \n",
    "X = df['features'].tolist()\n",
    "y = [0 if drug['LogS'] >= -1 else 1 if drug['LogS'] >= -3 else 2 for drug in data]\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# 初始化性能指标列表\n",
    "weighted_accuracy_scores = []\n",
    "weighted_precision_scores = []\n",
    "weighted_recall_scores = []\n",
    "weighted_l1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = np.array(X)[train_index], np.array(X)[test_index]\n",
    "    y_train, y_val = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = adaboost.predict(X_val)\n",
    "\n",
    "    t = classification_report(y_val,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "    print(t)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    weighted_accuracy_scores.append(accuracy)\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n",
    "    weighted_precision_scores.append(precision)\n",
    "    weighted_recall_scores.append(recall)\n",
    "    weighted_l1_scores.append(2 * (precision * recall) / (precision + recall)) \n",
    "\n",
    "mean_weighted_accuracy = sum(weighted_accuracy_scores) / len(weighted_accuracy_scores)\n",
    "mean_weighted_precision = sum(weighted_precision_scores) / len(weighted_precision_scores)\n",
    "mean_weighted_recall = sum(weighted_recall_scores) / len(weighted_recall_scores)\n",
    "mean_weighted_l1 = sum(weighted_l1_scores) / len(weighted_l1_scores)\n",
    "\n",
    "print(\"Mean weighted accuracy:\", mean_weighted_accuracy)\n",
    "print(\"Mean weighted precision:\", mean_weighted_precision)\n",
    "print(\"Mean weighted recall:\", mean_weighted_recall)\n",
    "print(\"Mean weighted L1 score:\", mean_weighted_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8118    0.6494    0.7216       425\n",
      "           1     0.6763    0.7266    0.7006       673\n",
      "           2     0.8106    0.8448    0.8273       831\n",
      "\n",
      "    accuracy                         0.7605      1929\n",
      "   macro avg     0.7662    0.7403    0.7498      1929\n",
      "weighted avg     0.7640    0.7605    0.7598      1929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8058    0.6526    0.7211       426\n",
      "           1     0.7039    0.7049    0.7044       698\n",
      "           2     0.7930    0.8719    0.8306       804\n",
      "\n",
      "    accuracy                         0.7630      1928\n",
      "   macro avg     0.7675    0.7431    0.7520      1928\n",
      "weighted avg     0.7636    0.7630    0.7607      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8435    0.6510    0.7348       447\n",
      "           1     0.6877    0.7382    0.7121       680\n",
      "           2     0.8113    0.8639    0.8368       801\n",
      "\n",
      "    accuracy                         0.7702      1928\n",
      "   macro avg     0.7808    0.7511    0.7612      1928\n",
      "weighted avg     0.7751    0.7702    0.7691      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8496    0.6443    0.7328       447\n",
      "           1     0.6823    0.7171    0.6993       668\n",
      "           2     0.7971    0.8696    0.8318       813\n",
      "\n",
      "    accuracy                         0.7645      1928\n",
      "   macro avg     0.7763    0.7437    0.7546      1928\n",
      "weighted avg     0.7695    0.7645    0.7629      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7964    0.6566    0.7198       399\n",
      "           1     0.7285    0.7255    0.7270       725\n",
      "           2     0.8039    0.8769    0.8388       804\n",
      "\n",
      "    accuracy                         0.7744      1928\n",
      "   macro avg     0.7763    0.7530    0.7619      1928\n",
      "weighted avg     0.7740    0.7744    0.7721      1928\n",
      "\n",
      "Mean weighted accuracy: 0.7665186205739434\n",
      "Mean weighted precision: 0.7692382219837884\n",
      "Mean weighted recall: 0.7665186205739434\n",
      "Mean weighted L1 score: 0.7678744054702517\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('/MSCSol-main/dataset/benchmark.json', 'r') as f:\n",
    "    data = json.load(f) \n",
    "df = pd.read_json('/MSCSol-main/dataset/benchmark.json')\n",
    "X = df['features'].tolist()\n",
    "y = [0 if drug['LogS'] >= -1 else 1 if drug['LogS'] >= -3 else 2 for drug in data]\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# 初始化性能指标列表\n",
    "weighted_accuracy_scores = []\n",
    "weighted_precision_scores = []\n",
    "weighted_recall_scores = []\n",
    "weighted_l1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = np.array(X)[train_index], np.array(X)[test_index]\n",
    "    y_train, y_val = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "    t = classification_report(y_val,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "    print(t)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    weighted_accuracy_scores.append(accuracy)\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n",
    "    weighted_precision_scores.append(precision)\n",
    "    weighted_recall_scores.append(recall)\n",
    "    weighted_l1_scores.append(2 * (precision * recall) / (precision + recall)) \n",
    "\n",
    "mean_weighted_accuracy = sum(weighted_accuracy_scores) / len(weighted_accuracy_scores)\n",
    "mean_weighted_precision = sum(weighted_precision_scores) / len(weighted_precision_scores)\n",
    "mean_weighted_recall = sum(weighted_recall_scores) / len(weighted_recall_scores)\n",
    "mean_weighted_l1 = sum(weighted_l1_scores) / len(weighted_l1_scores)\n",
    "\n",
    "print(\"Mean weighted accuracy:\", mean_weighted_accuracy)\n",
    "print(\"Mean weighted precision:\", mean_weighted_precision)\n",
    "print(\"Mean weighted recall:\", mean_weighted_recall)\n",
    "print(\"Mean weighted L1 score:\", mean_weighted_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f72649faee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    buf = (HMODULE * buf_count)()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6681    0.7356    0.7002       435\n",
      "           1     0.6187    0.6696    0.6432       681\n",
      "           2     0.8345    0.7319    0.7798       813\n",
      "\n",
      "    accuracy                         0.7107      1929\n",
      "   macro avg     0.7071    0.7124    0.7077      1929\n",
      "weighted avg     0.7208    0.7107    0.7136      1929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f72649fae50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    buf = (HMODULE * buf_count)()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6508    0.7354    0.6905       446\n",
      "           1     0.6495    0.6514    0.6504       697\n",
      "           2     0.8248    0.7618    0.7921       785\n",
      "\n",
      "    accuracy                         0.7158      1928\n",
      "   macro avg     0.7084    0.7162    0.7110      1928\n",
      "weighted avg     0.7212    0.7158    0.7174      1928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f72649faf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    buf = (HMODULE * buf_count)()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6474    0.7336    0.6878       428\n",
      "           1     0.6344    0.6362    0.6353       701\n",
      "           2     0.8122    0.7522    0.7810       799\n",
      "\n",
      "    accuracy                         0.7059      1928\n",
      "   macro avg     0.6980    0.7074    0.7014      1928\n",
      "weighted avg     0.7110    0.7059    0.7074      1928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f72649faf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    buf = (HMODULE * buf_count)()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6174    0.6893    0.6514       412\n",
      "           1     0.6165    0.6373    0.6267       714\n",
      "           2     0.8096    0.7369    0.7715       802\n",
      "\n",
      "    accuracy                         0.6898      1928\n",
      "   macro avg     0.6812    0.6878    0.6832      1928\n",
      "weighted avg     0.6970    0.6898    0.6922      1928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f72649faf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    \n",
      "  File \"/ifs/home/fanziyu/miniconda3/envs/pgmg2/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    buf = (HMODULE * buf_count)()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6505    0.6998    0.6743       423\n",
      "           1     0.6008    0.6820    0.6388       651\n",
      "           2     0.8474    0.7283    0.7834       854\n",
      "\n",
      "    accuracy                         0.7064      1928\n",
      "   macro avg     0.6996    0.7034    0.6988      1928\n",
      "weighted avg     0.7210    0.7064    0.7106      1928\n",
      "\n",
      "Mean weighted accuracy: 0.7057354013538717\n",
      "Mean weighted precision: 0.7141842060808361\n",
      "Mean weighted recall: 0.7057354013538717\n",
      "Mean weighted L1 score: 0.7099303852309987\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"threadpoolctl\")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('/MSCSol-main/dataset/benchmark.json', 'r') as f:\n",
    "    data = json.load(f) \n",
    "df = pd.read_json('/MSCSol-main/dataset/benchmark.json')\n",
    "X = df['features'].tolist()\n",
    "y = [0 if drug['LogS'] >= -1 else 1 if drug['LogS'] >= -3 else 2 for drug in data]\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# 初始化性能指标列表\n",
    "weighted_accuracy_scores = []\n",
    "weighted_precision_scores = []\n",
    "weighted_recall_scores = []\n",
    "weighted_l1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = np.array(X)[train_index], np.array(X)[test_index]\n",
    "    y_train, y_val = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn_classifier.predict(X_val)\n",
    "\n",
    "    t = classification_report(y_val,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "    print(t)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    weighted_accuracy_scores.append(accuracy)\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n",
    "    weighted_precision_scores.append(precision)\n",
    "    weighted_recall_scores.append(recall)\n",
    "    weighted_l1_scores.append(2 * (precision * recall) / (precision + recall)) \n",
    "\n",
    "mean_weighted_accuracy = sum(weighted_accuracy_scores) / len(weighted_accuracy_scores)\n",
    "mean_weighted_precision = sum(weighted_precision_scores) / len(weighted_precision_scores)\n",
    "mean_weighted_recall = sum(weighted_recall_scores) / len(weighted_recall_scores)\n",
    "mean_weighted_l1 = sum(weighted_l1_scores) / len(weighted_l1_scores)\n",
    "\n",
    "print(\"Mean weighted accuracy:\", mean_weighted_accuracy)\n",
    "print(\"Mean weighted precision:\", mean_weighted_precision)\n",
    "print(\"Mean weighted recall:\", mean_weighted_recall)\n",
    "print(\"Mean weighted L1 score:\", mean_weighted_l1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgmg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
