{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 0.5563427138863712, RMSE: 0.8392967395117668, MSE: 0.7044190169550825, R2: 0.8470792532269447\n",
      "Fold 2 - MAE: 0.63548018989159, RMSE: 0.932043521938954, MSE: 0.8687051267883694, R2: 0.804943033410362\n",
      "Fold 3 - MAE: 0.5704094469206721, RMSE: 0.8952729403012346, MSE: 0.8015136376356179, R2: 0.8110234375406146\n",
      "Fold 4 - MAE: 0.5751412311151983, RMSE: 0.8572249580568766, MSE: 0.7348346287156138, R2: 0.8323696027665828\n",
      "Fold 5 - MAE: 0.5586587810686972, RMSE: 0.8459547444845654, MSE: 0.7156394297159464, R2: 0.8439226464561433\n",
      "\n",
      "Average - MAE: 0.5792, RMSE: 0.8740, MSE: 0.7650, R2: 0.8279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./trained_models/regression_results/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./trained_models/regression_results/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "    metrics = np.zeros((folds, 4))\n",
    "\n",
    "    for i in range(1, folds+1):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        metrics[i-1] = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "    \n",
    "    for i in range(folds):\n",
    "        print(f\"Fold {i+1} - MAE: {metrics[i, 0]}, RMSE: {metrics[i, 1]}, MSE: {metrics[i, 2]}, R2: {metrics[i, 3]}\")\n",
    "\n",
    "  \n",
    "    mean_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"\\nAverage - MAE: {mean_metrics[0]:.4f}, RMSE: {mean_metrics[1]:.4f}, MSE: {mean_metrics[2]:.4f}, R2: {mean_metrics[3]:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8350    0.7757    0.8043       437\n",
      "           1     0.7510    0.8040    0.7766       694\n",
      "           2     0.8910    0.8709    0.8809       798\n",
      "\n",
      "    accuracy                         0.8253      1929\n",
      "   macro avg     0.8257    0.8169    0.8206      1929\n",
      "weighted avg     0.8280    0.8253    0.8260      1929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8304    0.7691    0.7986       433\n",
      "           1     0.7063    0.7958    0.7484       671\n",
      "           2     0.8975    0.8398    0.8677       824\n",
      "\n",
      "    accuracy                         0.8086      1928\n",
      "   macro avg     0.8114    0.8016    0.8049      1928\n",
      "weighted avg     0.8159    0.8086    0.8107      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8045    0.7647    0.7841       425\n",
      "           1     0.7452    0.7893    0.7666       693\n",
      "           2     0.8949    0.8728    0.8838       810\n",
      "\n",
      "    accuracy                         0.8190      1928\n",
      "   macro avg     0.8149    0.8090    0.8115      1928\n",
      "weighted avg     0.8212    0.8190    0.8197      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8428    0.7658    0.8025       427\n",
      "           1     0.7362    0.7916    0.7629       691\n",
      "           2     0.8871    0.8728    0.8799       810\n",
      "\n",
      "    accuracy                         0.8200      1928\n",
      "   macro avg     0.8220    0.8101    0.8151      1928\n",
      "weighted avg     0.8232    0.8200    0.8208      1928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8204    0.7796    0.7995       422\n",
      "           1     0.7527    0.7928    0.7722       695\n",
      "           2     0.8943    0.8767    0.8854       811\n",
      "\n",
      "    accuracy                         0.8252      1928\n",
      "   macro avg     0.8225    0.8164    0.8191      1928\n",
      "weighted avg     0.8271    0.8252    0.8258      1928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_data(fold):\n",
    "    y_pred = np.load(f'./trained_models/classification_results/y_pred_fold_{fold}.npy')\n",
    "    y_true = np.load(f'./trained_models/classification_results/y_true_fold_{fold}.npy')\n",
    "    return y_pred, y_true\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, mse, r2\n",
    "\n",
    "def main():\n",
    "    folds = 5\n",
    "\n",
    "    for i in range(0, folds):\n",
    "        y_pred, y_true = load_data(i)\n",
    "        from sklearn.metrics import classification_report\n",
    "        t = classification_report(y_true,y_pred, target_names=['0', '1', '2'],digits=4)\n",
    "        print(t)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgmg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
